import os
os.environ["OPENAI_API_KEY"] = "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"  # ì‹¤ì œ í‚¤

# í‚¤ê°€ ì˜ ë³´ì´ëŠ”ì§€(ë¹„ê³µê°œ ì„¸ì…˜ì´ë¯€ë¡œ printëŠ” ìƒëµ ê°€ëŠ¥)
assert os.getenv("OPENAI_API_KEY"), "í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ë¯¸ì„¤ì •"

# ê°„ë‹¨ í—¬ìŠ¤ì²´í¬: í´ë¼ì´ì–¸íŠ¸ ìƒì„±
from openai import OpenAI
cli = OpenAI()
# ëª¨ë¸ ì ‘ê·¼ê¶Œí•œ ì´ìŠˆê°€ ìˆìœ¼ë©´ ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆì–´ìš”.

import json
import argparse
import re
from typing import List, Dict, Any, Tuple, Optional, Set
from urllib.parse import urlparse
from pydantic import BaseModel, Field
import time
import os
from openai import OpenAI

# ===== (ì„ íƒ) OpenAI - API í‚¤ ê³µë€ìœ¼ë¡œ ë‘  =====
#OPENAI_MODEL = "gpt-4o-mini"  # ì˜ˆì‹œ (í•„ìš” ì‹œ ë³€ê²½)
OPENAI_MODEL = "gpt-5"  # ì˜ˆì‹œ (í•„ìš” ì‹œ ë³€ê²½)



# 1) í™˜ê²½ë³€ìˆ˜ì—ì„œ ìš°ì„  ì½ê³ , ë¹„ì—ˆìœ¼ë©´ ê¸°ì¡´ ìƒìˆ˜ ì‚¬ìš©
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL") or OPENAI_MODEL


def _get_openai_client():
    """
    OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ìƒì„±í•˜ê³ , ì‹¤íŒ¨ ì‹œ (None, reason) ë°˜í™˜.
    """
    if not _openai_available:
        return None, "openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai"

    key = OPENAI_API_KEY
    if not key:
        return None, "OPENAI_API_KEYê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ìƒìˆ˜ì— í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”."

    try:
        # v1 SDKëŠ” ë³´í†µ í™˜ê²½ë³€ìˆ˜ë¡œ í‚¤ë¥¼ ì½ìŠµë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ëŸ°íƒ€ì„ì— í‚¤ë¥¼ ì£¼ì…í•´ë„ ë˜ë„ë¡ envì— ê½‚ì•„ì¤ë‹ˆë‹¤.
        os.environ["OPENAI_API_KEY"] = key
        client = OpenAI()  # api_key ì¸ìë¥¼ ìƒëµí•˜ê³  env ì‚¬ìš©
        return client, None
    except Exception as e:
        return None, f"OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e!r}"


try:
    _openai_available = True
except Exception:
    _openai_available = False
    OpenAI = None
# -------------------------
# ìœ í‹¸
# -------------------------
def uniq(seq): # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ë©° ìˆœì„œ ë³´ì¡´
    seen = set()
    out = []
    for x in seq:
        if x not in seen:
            seen.add(x)
            out.append(x)
    return out

def top_base(url: str) -> str: # URLì—ì„œ scheme://host/ë§Œ ì¶”ì¶œ (http://example.com/abc -> http://example.com/)
    try:
        u = urlparse(url)
        return f"{u.scheme}://{u.netloc}/"
    except Exception:
        return url

def suggest_templates_for(tag: str) -> List[str]: # nuclei ì‹¤í–‰ì„ ìœ„í•œ í…œí”Œë¦¿ íƒœê·¸ë¥¼ ìƒì„± (ì˜ˆ: "tags:login")
    return [f"tags:{tag}"]

# -------------------------
# ê°ì§€ê¸° (í¬ë¡¤ëŸ¬ JSON -> ì›ì‹œ findings)
# -------------------------
ALLOW_TAGS_ALL = {
    "panel", "login",
    "wordpress", "wp-plugins", "cms", "joomla",
    "tech",
    "exposure", "info-leak", "logs", "debug",
    "osint", "osint-social", "listing"
}

def detect_panel_login(report: Dict[str, Any]) -> List[Dict[str, Any]]: # title, form, ë§í¬ë¥¼ ë¶„ì„í•´ì„œ ê´€ë¦¬ì í˜ì´ì§€(panel) ë˜ëŠ” ë¡œê·¸ì¸(login) ê°€ëŠ¥ì„±ì„ íƒì§€
    findings = []
    dom = report.get("dom", {})
    forms = dom.get("forms", []) or []
    title = (dom.get("title") or "").lower()
    visible_links = dom.get("visible_links", []) or []

    # ë¡œê·¸ì¸ í¼ ì¶”ì •
    login_forms = []
    for f in forms:
        inputs = set((f.get("inputs") or []))
        if "password" in inputs or {"username", "password"} & inputs:
            login_forms.append(f)

    # í›„ë³´ íƒ€ê²Ÿ
    candidates = []
    for href in visible_links:
        p = urlparse(href).path.lower()
        if any(k in p for k in ["/admin", "/wp-admin", "/wp-login.php", "/login", "/user/login", "/dashboard"]):
            candidates.append(href)

    # panel
    if "admin" in title or any("/admin" in urlparse(x).path.lower() for x in candidates):
        findings.append({
            "tag": "panel",
            "confidence": "high",
            "reason": "íƒ€ì´í‹€/ë§í¬ì—ì„œ ê´€ë¦¬ì íŒ¨í„´ ê°ì§€",
            "targets": uniq(candidates)[:10],
            "suggested_templates": suggest_templates_for("panel") + suggest_templates_for("login")
        })

    # login
    if login_forms or "login" in title or candidates:
        reasons = []
        for f in login_forms[:2]:
            reasons.append(f"ë¡œê·¸ì¸ í¼(action={f.get('action')}, method={f.get('method')})")
        if "login" in title:
            reasons.append("íƒ€ì´í‹€ í‚¤ì›Œë“œ 'login'")
        if candidates:
            reasons.append("ë¡œê·¸ì¸/íŒ¨ë„ í›„ë³´ ë§í¬ ì¡´ì¬")
        targets = [f.get("action") for f in login_forms if f.get("action")] + candidates
        targets = uniq(targets)[:10]
        findings.append({
            "tag": "login",
            "confidence": "high" if login_forms else "medium",
            "reason": "; ".join(reasons) or "ë¡œê·¸ì¸ ê´€ë ¨ ì‹ í˜¸",
            "targets": targets or [top_base(report.get("url", ""))],
            "suggested_templates": suggest_templates_for("login")
        })
    return findings

def detect_cms_stack(report: Dict[str, Any]) -> List[Dict[str, Any]]: # meta íƒœê·¸, script/link ê²½ë¡œ ë“±ì„ ë¶„ì„í•´ WordPress, Drupal, Jommla ê°™ì€ CMS í”ì ì„ íƒì§€
    findings = []
    dom = report.get("dom", {})
    meta = dom.get("meta", {}) or {}
    scripts = dom.get("scripts", []) or []
    links = dom.get("links", []) or []

    # WordPress í”ì 
    wp = ("generator" in meta and "wordpress" in str(meta.get("generator", "")).lower()) \
         or any("/wp-content/" in u or "/wp-includes/" in u for u in scripts + links)
    if wp:
        findings.append({
            "tag": "wordpress",
            "confidence": "high",
            "reason": "meta.generator ë˜ëŠ” /wp-content/ ê²½ë¡œ",
            "targets": [top_base(report.get("url", ""))],
            "suggested_templates": suggest_templates_for("wordpress") + ["tags:wp", "tags:wp-plugin"]
        })
        wp_plugins = [u for u in scripts + links if "/wp-content/plugins/" in u]
        if wp_plugins:
            findings.append({
                "tag": "wp-plugins",
                "confidence": "medium",
                "reason": f"í”ŒëŸ¬ê·¸ì¸ ê²½ë¡œ {len(wp_plugins)}ê°œ ë…¸ì¶œ",
                "targets": uniq(wp_plugins)[:20],
                "suggested_templates": ["tags:wp-plugins", "tags:wp-plugin"]
            })

    # ê¸°íƒ€ CMS í”ì 
    drupal = any("/sites/default/" in u for u in scripts + links)
    if drupal:
        findings.append({
            "tag": "cms",
            "confidence": "medium",
            "reason": "Drupal íŒ¨í„´(/sites/default/) ê°ì§€",
            "targets": [top_base(report.get("url", ""))],
            "suggested_templates": ["tags:cms"]
        })
    joomla = any("joomla" in u.lower() for u in scripts + links)
    if joomla:
        findings.append({
            "tag": "joomla",
            "confidence": "medium",
            "reason": "ë¦¬ì†ŒìŠ¤ ê²½ë¡œì— 'joomla'",
            "targets": [top_base(report.get("url", ""))],
            "suggested_templates": ["tags:joomla", "tags:cms"]
        })
    return findings

def detect_tech(report: Dict[str, Any]) -> List[Dict[str, Any]]: # fingerprints í•„ë“œì—ì„œ ì„œë²„ ê¸°ìˆ  ìŠ¤íƒ(nginx, php ë“±)ì„ ì¶”ì¶œ
    fp = report.get("fingerprints", {}) or {}
    techs = fp.get("tech", []) or []
    if not techs:
        return []
    return [{
        "tag": "tech",
        "confidence": "medium",
        "reason": f"ê¸°ìˆ  ìŠ¤íƒ: {', '.join(techs[:6])}",
        "targets": [top_base(report.get("url", ""))],
        "suggested_templates": suggest_templates_for("tech")
    }]

def detect_exposure(report: Dict[str, Any]) -> List[Dict[str, Any]]: # DOMì˜ ì£¼ì„/í…ìŠ¤íŠ¸ ë‹¨ì„œì—ì„œ API í‚¤, ë¡œê·¸, debug ë©”ì‹œì§€ ë“± ë¯¼ê° ì •ë³´ ë…¸ì¶œì„ íƒì§€
    leaks = (report.get("dom", {}) or {}).get("comments_or_text_leaks", []) or []
    exposure, info_leak, logs, debug = [], [], [], []
    for l in leaks:
        t = (l.get("type") or "").lower()
        if t in ["api_key", "apikey", "secret", "token"]:
            exposure.append(l)
        elif t in ["stack", "warning", "traceback", "exception", "log"]:
            logs.append(l)
        elif t == "debug":
            debug.append(l)
        else:
            info_leak.append(l)
    out = []
    if exposure:
        out.append({
            "tag": "exposure",
            "confidence": "high",
            "reason": "ë¯¼ê° ì •ë³´(API/Secret ë“±) ë…¸ì¶œ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": exposure[:5],
            "suggested_templates": ["tags:exposure", "tags:info-leak"]
        })
    if info_leak:
        out.append({
            "tag": "info-leak",
            "confidence": "medium",
            "reason": "ì£¼ì„/í…ìŠ¤íŠ¸ì˜ ì •ë³´ ëˆ„ì¶œ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": info_leak[:5],
            "suggested_templates": ["tags:info-leak"]
        })
    if logs:
        out.append({
            "tag": "logs",
            "confidence": "medium",
            "reason": "ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤/ê²½ê³ /ë¡œê·¸ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": logs[:5],
            "suggested_templates": ["tags:logs"]
        })
    if debug:
        out.append({
            "tag": "debug",
            "confidence": "medium",
            "reason": "DEBUG í”Œë˜ê·¸ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": debug[:5],
            "suggested_templates": ["tags:debug"]
        })
    return out

def detect_osint(report: Dict[str, Any]) -> List[Dict[str, Any]]: # OSINT ë…¸ì¶œ ì •ë³´(ì´ë©”ì¼, ì†Œì…œ ë§í¬, ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŒ… ë“±)ë¥¼ íƒì§€
    osint = report.get("osint_exposure", {}) or {}
    emails = osint.get("emails", []) or []
    socials = osint.get("socials", []) or []
    open_dirs = osint.get("open_directory_ui", []) or []
    out = []
    if emails:
        out.append({
            "tag": "osint",
            "confidence": "high",
            "reason": "ë³´ì•ˆ/ì—°ë½ ì´ë©”ì¼",
            "targets": [top_base(report.get("url", ""))],
            "evidence": {"emails": emails[:10]},
            "suggested_templates": ["tags:osint"]
        })
    if socials:
        out.append({
            "tag": "osint-social",
            "confidence": "high",
            "reason": "ê³µì‹ ì†Œì…œ ë§í¬",
            "targets": socials[:10],
            "evidence": {"socials": socials[:10]},
            "suggested_templates": ["tags:osint-social"]
        })
    if open_dirs:
        out.append({
            "tag": "listing",
            "confidence": "medium",
            "reason": "ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŒ… UI",
            "targets": open_dirs[:10],
            "suggested_templates": ["tags:listing"]
        })
    return out

def build_raw_findings(report: Dict[str, Any]) -> List[Dict[str, Any]]: # ìœ„ì˜ ëª¨ë“  ê°ì§€ê¸°ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì›ì‹œ findings ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¦
    detectors = [detect_panel_login, detect_cms_stack, detect_tech, detect_exposure, detect_osint]
    findings = []
    for det in detectors:
        findings.extend(det(report))
    return findings

# -------------------------
# LLM ê²Œì´íŠ¸ (ë³´ì•ˆ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§)
# -------------------------
class LLMFindingDecision(BaseModel): # ë‹¨ì¼ findingì— ëŒ€í•œ LLM íŒì • êµ¬ì¡°ì²´ (tag, severity, run ì—¬ë¶€, rationale, references ë“±ì„ í¬í•¨)
    tag: str
    looks_vulnerable: bool
    severity: str = Field(..., description="one of: none, low, medium, high, critical")
    rationale: str
    references: List[str] = Field(default_factory=list)  # ex) OWASP, CWE ë§í¬ ë“±
    run_template: bool = Field(..., description="nuclei ì‹¤í–‰ ê°€ì¹˜ ì—¬ë¶€")

class LLMGateOutput(BaseModel): # LLM ì „ì²´ íŒì • ê²°ê³¼ êµ¬ì¡°ì²´(ì „ì²´ ìœ„í—˜ë„, ê°œë³„ decisions ë¦¬ìŠ¤íŠ¸)
    overall_risk: str = Field(..., description="none|low|medium|high|critical")
    decisions: List[LLMFindingDecision]

SYSTEM_PROMPT = """You are a defensive security triage assistant.
RULES:
- If any URLs include known vulnerable patterns (e.g., /sqli/, /fi/, /phpinfo.php, ?page=), elevate severity to 'high' AND set run_template=true.
- Do NOT fabricate data or payloads, but do suggest scanner template tags such as 'sqli', 'lfi', or 'debug-info-leak' if patterns match known vulnerability classes.
- Output STRICT JSON only, no markdown, no commentary.
- If evidence suggests sensitive info exposure (e.g., API keys, secrets, debug logs), elevate risk.
- If the input includes potentially sensitive endpoints (e.g., login.php, admin/, debug/, test/, api/token), increase severity.
- If the input contains SQL keywords (e.g., SELECT, UNION, WHERE) or suspect query params (e.g., ?id=, ?q=), flag as 'medium' or higher.
- NEVER attempt active exploitation or generate attack payloads.
- Base your analysis ONLY on the provided JSON; do NOT fabricate.
- Cite public references (e.g., OWASP, CWE) in 'references' when relevant.
- If the LLM detects known vulnerable paths (e.g., /sqli/, /fi/?page=, /phpinfo.php), and severity is high, then set run_template=true regardless of raw finding presence.
- In such cases, recommend generic scanner tags (e.g., 'sqli', 'lfi', 'debug-info-leak') in suggested_templates.
- Do NOT generate payloads or active tests.
"""

USER_PROMPT_TEMPLATE = """Input JSON (from crawler):
{crawler_json}

Task:
For each finding candidate below, decide if it looks vulnerable in a way that justifies running a nuclei template. Consider severity (none|low|medium|high|critical) and set run_template true/false.

Candidates:
{candidates_json}

Output JSON schema:
{{
  "overall_risk": "none|low|medium|high|critical",
  "decisions": [
    {{
      "tag": "<string>",
      "looks_vulnerable": <true|false>,
      "severity": "none|low|medium|high|critical",
      "rationale": "<short reason>",
      "references": ["<optional refs>"],
      "run_template": <true|false>
    }}
  ]
}}
"""

# --- ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° í˜¸í™˜ ì²˜ë¦¬: gpt-5 ê³„ì—´ì€ temperature/top_p ë“± ë¯¸ì§€ì› ---
def _sampling_supported(model: str) -> bool:
    return not model.lower().startswith("gpt-5")

def _postprocess_and_fill_missing(raw_findings: List[Dict[str, Any]], llm_out: Dict[str, Any]) -> LLMGateOutput:
    """
    LLMì´ ì¼ë¶€ tagë§Œ íŒë‹¨í–ˆì„ ê²½ìš°, ëˆ„ë½ëœ tagëŠ” conservative defaultë¡œ ì±„ìš´ë‹¤.
    """
    try:
        parsed = LLMGateOutput(**llm_out)
    except Exception as e:
        raise ValueError(f"LLM output schema validation failed: {e}")

    decided_tags = {d.tag for d in parsed.decisions}
    all_tags = [f["tag"] for f in raw_findings]
    missing = [t for t in all_tags if t not in decided_tags]

    if missing:
        for t in missing:
            parsed.decisions.append(LLMFindingDecision(
                tag=t,
                looks_vulnerable=False,
                severity="low",
                rationale="no decision returned; defaulting to conservative low/no-run",
                references=[],
                run_template=False
            ))
        # overall_risk ì¬ê³„ì‚°(ê°€ì¥ ë†’ì€ severity)
        sev_rank = {"none":0,"low":1,"medium":2,"high":3,"critical":4}
        max_sev = "none"
        for d in parsed.decisions:
            if sev_rank.get(d.severity, 0) > sev_rank.get(max_sev, 0):
                max_sev = d.severity
        parsed.overall_risk = max_sev

    return parsed


def call_llm_gate(
    crawler_report: Dict[str, Any],
    raw_findings: List[Dict[str, Any]],
    max_candidates_per_call: Optional[int] = None  # ë„ˆë¬´ í° ì…ë ¥ì´ë©´ ë¶„í•  (ê¸°ë³¸: ì „ì²´ 1íšŒ)
) -> Optional[LLMGateOutput]:
    """
    OpenAI APIë¡œ findingsì˜ ìŠ¤ìº” ê°€ì¹˜/ì‹¬ê°ë„ë¥¼ íŒì •.
    - ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° í˜¸í™˜ ì²˜ë¦¬(ì˜ˆ: gpt-5*ëŠ” temperature/top_p ë¯¸ì§€ì›)
    - JSON íŒŒì‹± ê²¬ê³ í™” ë° ëˆ„ë½ íƒœê·¸ ë³´ì •
    - ì‹¤íŒ¨ ì‹œ None ë°˜í™˜(íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í´ë°±)
    """
    client, why = _get_openai_client()
    if client is None:
        print(f"[LLM GATE FALLBACK] {why}")
        return None

    # í›„ë³´ ë¶„í• (ì˜µì…˜) â€” ê¸°ë³¸ì€ ì „ì²´ í•œ ë²ˆì—
    batches: List[List[Dict[str, Any]]] = []
    if max_candidates_per_call and max_candidates_per_call > 0:
        for i in range(0, len(raw_findings), max_candidates_per_call):
            batches.append(raw_findings[i:i+max_candidates_per_call])
    else:
        batches = [raw_findings]

    # ê° ë°°ì¹˜ë¥¼ í˜¸ì¶œ í›„ ë³‘í•©
    merged_decisions: List[LLMFindingDecision] = []
    overall_max = "none"
    sev_rank = {"none":0,"low":1,"medium":2,"high":3,"critical":4}

    for batch_idx, batch in enumerate(batches):
        user_prompt = USER_PROMPT_TEMPLATE.format(
            crawler_json=json.dumps(crawler_report, ensure_ascii=False, indent=2),
            candidates_json=json.dumps(batch, ensure_ascii=False, indent=2),
        )

        # gpt-5*ëŠ” sampling íŒŒë¼ë¯¸í„° ì œê±°
        kwargs = {}
        # if _sampling_supported(OPENAI_MODEL):
        #     kwargs["temperature"] = 0.2

        last_err = None
        for attempt in range(2):
            try:
                resp = client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt}
                    ],
                    **kwargs
                )
                text = resp.choices[0].message.content.strip()
                m = re.search(r"\{.*\}\s*$", text, re.S)
                raw_json = m.group(0) if m else text
                data = json.loads(raw_json)
                parsed = _postprocess_and_fill_missing(batch, data)

                # ë³‘í•©
                merged_decisions.extend(parsed.decisions)
                if sev_rank.get(parsed.overall_risk, 0) > sev_rank.get(overall_max, 0):
                    overall_max = parsed.overall_risk
                break  # ë°°ì¹˜ ì„±ê³µí–ˆìœ¼ë©´ ë‹¤ìŒ ë°°ì¹˜ë¡œ
            except Exception as e:
                last_err = e
                time.sleep(0.5)
        else:
            print(f"[LLM GATE FALLBACK] batch {batch_idx} failed: {type(last_err).__name__}: {last_err}")
            return None  # ë°°ì¹˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í´ë°±

    # ìµœì¢… ë³‘í•© ê²°ê³¼(ë™ì¼ tag ì¤‘ë³µ ì‹œ ë§ˆì§€ë§‰ê°’ ìœ ì§€)
    final_by_tag: Dict[str, LLMFindingDecision] = {}
    for d in merged_decisions:
        final_by_tag[d.tag] = d
    final = LLMGateOutput(overall_risk=overall_max, decisions=list(final_by_tag.values()))
    return final

# -------------------------
# íœ´ë¦¬ìŠ¤í‹± ê²Œì´íŠ¸ (LLM ë¶ˆê°€ ì‹œ)
# -------------------------
SEV_ORDER = ["none", "low", "medium", "high", "critical"]

def heuristic_gate(raw_findings: List[Dict[str, Any]]) -> LLMGateOutput:
    decisions = []
    # ë‹¨ìˆœ ì •ì±…: exposure > panel/login > wp-plugins > wordpress > tech > others
    for f in raw_findings:
        tag = f["tag"]
        sev = "low"
        run = False

        if tag == "exposure":
            sev, run = "high", True
        elif tag in ("panel", "login"):
            sev, run = "medium", True
        elif tag in ("wp-plugins",):
            sev, run = "medium", True
        elif tag in ("wordpress", "cms", "joomla"):
            sev, run = "low", True
        elif tag in ("logs", "debug", "info-leak"):
            sev, run = "medium", True
        elif tag in ("tech", "osint", "osint-social", "listing"):
            sev, run = "low", False  # ì •ë³´ì„±

        decisions.append(LLMFindingDecision(
            tag=tag,
            looks_vulnerable=run,
            severity=sev,
            rationale="heuristic decision (no-LLM)",
            references=[],
            run_template=run
        ))

    # overall_risk = ìµœê³  ë“±ê¸‰
    max_sev = "none"
    for d in decisions:
        if SEV_ORDER.index(d.severity) > SEV_ORDER.index(max_sev):
            max_sev = d.severity

    return LLMGateOutput(overall_risk=max_sev, decisions=decisions)

# -------------------------
# nuclei ì‹¤í–‰/ë¯¸ì‹¤í–‰ ë¶„ë¦¬
# -------------------------
def split_to_run_skip(raw_findings: List[Dict[str, Any]], # findingsë¥¼ to_run(ìŠ¤ìºë‹ ì‹¤í–‰)ê³¼ to_skip(ì‹¤í–‰ ì œì™¸)ìœ¼ë¡œ ë‚˜ëˆˆë‹¤.
                      gate: LLMGateOutput,
                      allow_tags: Set[str]) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    to_run, to_skip = [], []
    # tag -> run_template ë§µ
    runmap = {d.tag: d.run_template for d in gate.decisions}
    sevmap = {d.tag: d.severity for d in gate.decisions}
    ratemap = {d.tag: d.rationale for d in gate.decisions}

    for f in raw_findings:
        tag = f["tag"]
        f["llm_severity"] = sevmap.get(tag, "low")
        f["llm_rationale"] = ratemap.get(tag, "decision missing")
        if tag in allow_tags and runmap.get(tag, False):
            to_run.append(f)
        else:
            to_skip.append(f)
    return to_run, to_skip

import os
import json
import argparse
from typing import Dict, Any, Optional

# ---- ê³µí†µ ì„¤ì • ----
DEFAULT_ALLOW = ",".join(sorted(ALLOW_TAGS_ALL)) # í—ˆìš©ë˜ëŠ” íƒœê·¸ ì „ì²´ ëª©ë¡ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¬¸ìì—´ë¡œ ë³´ê´€

def in_notebook() -> bool:
    """Jupyter/Colabì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ íŒë³„."""
    try:
        from IPython import get_ipython  # noqa
        return True
    except Exception:
        return False

def run_pipeline_from_report(report: Dict[str, Any], allow: str = DEFAULT_ALLOW) -> Dict[str, Any]:
    allow_tags = set([t.strip() for t in (allow or "").split(",") if t.strip()])
    raw_findings = build_raw_findings(report)

    # ğŸ”¥ ì™„í™” ì •ì±…: ë„ˆë¬´ findingsê°€ ì ìœ¼ë©´ LLM ì‹œë„ ìœ ë„
    if len(raw_findings) == 0:
        print("[â„¹ï¸] Finding ì—†ìŒ: LLM ê¸°ë°˜ íƒìƒ‰ ì‹œë„ ì¤‘...")
        dummy_finding = {
            "tag": "minimal-check",
            "confidence": "low",
            "reason": "No raw finding; sending dummy input to LLM for conservative check",
            "targets": [top_base(report.get("url", ""))],
            "suggested_templates": []
        }
        raw_findings = [dummy_finding]

    gate = call_llm_gate(report, raw_findings) or heuristic_gate(raw_findings)
    to_run, to_skip = split_to_run_skip(raw_findings, gate, allow_tags)
    return {"overall_risk": gate.overall_risk, "to_run": to_run, "to_skip": to_skip}


def run_pipeline_from_file(crawler_json_path: str, allow: str = DEFAULT_ALLOW) -> Dict[str, Any]:
    """íŒŒì¼ ê²½ë¡œë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰."""
    with open(crawler_json_path, "r", encoding="utf-8") as f:
        report = json.load(f)
    return run_pipeline_from_report(report, allow=allow)

def main(crawler_json: Optional[str] = None,
         allow: str = DEFAULT_ALLOW,
         report_obj: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    ê³µí†µ ì§„ì…ì :
    - ë…¸íŠ¸ë¶ì—ì„œëŠ” main(report_obj=...) ë˜ëŠ” main(crawler_json=...)ë¡œ ì§ì ‘ í˜¸ì¶œ
    - .py CLIì—ì„œëŠ” argparseë¡œ ê°’ì„ ë°›ì•„ main(crawler_json=...) í˜¸ì¶œ
    """
    if report_obj is not None:
        return run_pipeline_from_report(report_obj, allow=allow)
    if crawler_json:
        return run_pipeline_from_file(crawler_json, allow=allow)
    raise ValueError("main()ì—ëŠ” crawler_json(íŒŒì¼ ê²½ë¡œ) ë˜ëŠ” report_obj(dict) ì¤‘ í•˜ë‚˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

def main_cli() -> None:
    import argparse

    ap = argparse.ArgumentParser()
    ap.add_argument("crawler_json", help="crawler report json path")
    ap.add_argument("--allow", type=str, default=DEFAULT_ALLOW,
                    help="comma-separated tags to allow")
    ap.add_argument("--author", type=str, default="ksko", help="YAML author metadata")
    ap.add_argument("--id-prefix", type=str, default="auto-gen", help="YAML id prefix")
    ap.add_argument("--out", type=str, help="YAML íŒŒì¼ ì €ì¥ ê²½ë¡œ (ì˜ˆ: nuclei_auto.yaml)")
    ap.add_argument("--print-json", action="store_true", help="JSON ê²°ê³¼ë„ ì¶œë ¥")
    args = ap.parse_args()

    # ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    out = main(crawler_json=args.crawler_json, allow=args.allow)

    if args.print_json:
        print(json.dumps(out, ensure_ascii=False, indent=2))

    # nuclei YAML ìƒì„±
    yaml_out = findings_to_nuclei_yaml(
        out,
        base_id_prefix=args.id_prefix,
        author=args.author
    )

    if args.out:
        with open(args.out, "w", encoding="utf-8") as f:
            f.write(yaml_out)
        print(f"[âœ“] YAML ì €ì¥ ì™„ë£Œ: {args.out}")
    else:
        print(yaml_out)

import re, yaml, json
from urllib.parse import urlparse
from typing import Dict, Any, List, Optional

def _to_rel_path(u: str) -> str:
    if re.match(r"^https?://", u, re.I):
        p = urlparse(u).path or "/"
        if not p.startswith("/"):
            p = "/" + p
        return "{{BaseURL}}" + p
    if not u.startswith("/"):
        u = "/" + u
    return "{{BaseURL}}" + u

def _only_urls(refs: List[str]) -> List[str]:
    return [r for r in (refs or []) if r.startswith("http")]

def _basic_matchers_for(tag: str):
    tag = (tag or "").lower()
    if tag in ("panel", "login"):
        return {
            "matchers-condition": "and",
            "matchers": [
                {"type": "status", "status": [200, 302, 401, 403]},
                {"type": "word", "words": ["login", "admin", "sign in"], "condition": "or", "part": "body"}
            ]
        }
    if tag in ("wordpress", "wp-plugins"):
        return {
            "matchers-condition": "and",
            "matchers": [
                {"type": "status", "status": [200, 302]},
                {"type": "word", "words": ["/wp-content/", "WordPress"], "condition": "or", "part": "body"}
            ]
        }
    if tag in ("exposure", "logs", "listing"):
        return {
            "matchers-condition": "or",
            "matchers": [
                {"type": "status", "status": [200]},
                {"type": "word", "words": ["Index of /", "Traceback", "Warning:"], "part": "body"}
            ]
        }
    return {"matchers": [{"type": "status", "status": [200, 302, 401, 403]}]}

def findings_to_nuclei_yaml(
    pipeline_out: Dict[str, Any],
    base_id_prefix: str = "auto-gen",
    author: str = "ksko",
    add_metadata: Optional[Dict[str, Any]] = None
) -> str:
    add_metadata = add_metadata or {"source": "auto-pipeline"}
    findings = pipeline_out.get("to_run", []) or []
    yamls = []
    for idx, f in enumerate(findings, 1):
        tag = f.get("tag", "unknown")
        sev = (f.get("llm_severity") or "low").lower()
        rationale = f.get("llm_rationale") or f.get("reason") or ""
        refs = _only_urls(f.get("suggested_templates") or [])
        targets = f.get("targets") or []

        paths, seen = [], set()
        for t in targets:
            p = _to_rel_path(str(t))
            if p not in seen:
                seen.add(p)
                paths.append(p)

        tpl = {
            "id": f"{base_id_prefix}-{tag}-{idx}",
            "info": {
                "name": f"Auto-detected {tag}",
                "author": author,
                "severity": sev,
                "description": rationale,
                "reference": refs,
                "tags": [tag],
                "metadata": {**add_metadata, "rule": tag}
            },
            "http": []
        }
        if paths:
            http_block = {
                "method": "GET",
                "path": paths,
                "redirects": True,
                "max-redirects": 2,
                "stop-at-first-match": True,
            }
            http_block.update(_basic_matchers_for(tag))
            tpl["http"].append(http_block)
        yamls.append(tpl)
    return yaml.dump_all(yamls, sort_keys=False, allow_unicode=True)

if __name__ == "__main__":

    main_cli()