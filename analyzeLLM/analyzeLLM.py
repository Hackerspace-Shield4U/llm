import json
import argparse
import re
from typing import List, Dict, Any, Tuple, Optional, Set
from urllib.parse import urlparse
from pydantic import BaseModel, Field
import time
import os
from openai import OpenAI

# ===== (ì„ íƒ) OpenAI - API í‚¤ ê³µë€ìœ¼ë¡œ ë‘  =====
#OPENAI_MODEL = "gpt-4o-mini"  # ì˜ˆì‹œ (í•„ìš” ì‹œ ë³€ê²½)
OPENAI_MODEL = "gpt-5"  # ì˜ˆì‹œ (í•„ìš” ì‹œ ë³€ê²½)



# 1) í™˜ê²½ë³€ìˆ˜ì—ì„œ ìš°ì„  ì½ê³ , ë¹„ì—ˆìœ¼ë©´ ê¸°ì¡´ ìƒìˆ˜ ì‚¬ìš©
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL") or OPENAI_MODEL


def _get_openai_client():
    """
    OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ìƒì„±í•˜ê³ , ì‹¤íŒ¨ ì‹œ (None, reason) ë°˜í™˜.
    """
    if not _openai_available:
        return None, "openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai"

    key = OPENAI_API_KEY
    if not key:
        return None, "OPENAI_API_KEYê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ìƒìˆ˜ì— í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”."

    try:
        # v1 SDKëŠ” ë³´í†µ í™˜ê²½ë³€ìˆ˜ë¡œ í‚¤ë¥¼ ì½ìŠµë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ëŸ°íƒ€ì„ì— í‚¤ë¥¼ ì£¼ì…í•´ë„ ë˜ë„ë¡ envì— ê½‚ì•„ì¤ë‹ˆë‹¤.
        os.environ["OPENAI_API_KEY"] = key
        client = OpenAI()  # api_key ì¸ìë¥¼ ìƒëµí•˜ê³  env ì‚¬ìš©
        return client, None
    except Exception as e:
        return None, f"OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e!r}"


try:
    _openai_available = True
except Exception:
    _openai_available = False
    OpenAI = None
# -------------------------
# ìœ í‹¸
# -------------------------
def uniq(seq): # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ë©° ìˆœì„œ ë³´ì¡´
    seen = set()
    out = []
    for x in seq:
        if x not in seen:
            seen.add(x)
            out.append(x)
    return out

def top_base(url: str) -> str: # URLì—ì„œ scheme://host/ë§Œ ì¶”ì¶œ (http://example.com/abc -> http://example.com/)
    try:
        u = urlparse(url)
        return f"{u.scheme}://{u.netloc}/"
    except Exception:
        return url

def suggest_templates_for(tag: str) -> List[str]: # nuclei ì‹¤í–‰ì„ ìœ„í•œ í…œí”Œë¦¿ íƒœê·¸ë¥¼ ìƒì„± (ì˜ˆ: "tags:login")
    return [f"tags:{tag}"]

# -------------------------
# ê°ì§€ê¸° (í¬ë¡¤ëŸ¬ JSON -> ì›ì‹œ findings)
# -------------------------
ALLOW_TAGS_ALL = {
    "panel", "login",
    "wordpress", "wp-plugins", "cms", "joomla",
    "tech",
    "exposure", "info-leak", "logs", "debug",
    "osint", "osint-social", "listing"
}

def detect_panel_login(report: Dict[str, Any]) -> List[Dict[str, Any]]: # title, form, ë§í¬ë¥¼ ë¶„ì„í•´ì„œ ê´€ë¦¬ì í˜ì´ì§€(panel) ë˜ëŠ” ë¡œê·¸ì¸(login) ê°€ëŠ¥ì„±ì„ íƒì§€
    findings = []
    dom = report.get("dom", {})
    forms = dom.get("forms", []) or []
    title = (dom.get("title") or "").lower()
    visible_links = dom.get("visible_links", []) or []

    # ë¡œê·¸ì¸ í¼ ì¶”ì •
    login_forms = []
    for f in forms:
        inputs = set((f.get("inputs") or []))
        if "password" in inputs or {"username", "password"} & inputs:
            login_forms.append(f)

    # í›„ë³´ íƒ€ê²Ÿ
    candidates = []
    for href in visible_links:
        p = urlparse(href).path.lower()
        if any(k in p for k in ["/admin", "/wp-admin", "/wp-login.php", "/login", "/user/login", "/dashboard"]):
            candidates.append(href)

    # panel
    if "admin" in title or any("/admin" in urlparse(x).path.lower() for x in candidates):
        findings.append({
            "tag": "panel",
            "confidence": "high",
            "reason": "íƒ€ì´í‹€/ë§í¬ì—ì„œ ê´€ë¦¬ì íŒ¨í„´ ê°ì§€",
            "targets": uniq(candidates)[:10],
            "suggested_templates": suggest_templates_for("panel") + suggest_templates_for("login")
        })

    # login
    if login_forms or "login" in title or candidates:
        reasons = []
        for f in login_forms[:2]:
            reasons.append(f"ë¡œê·¸ì¸ í¼(action={f.get('action')}, method={f.get('method')})")
        if "login" in title:
            reasons.append("íƒ€ì´í‹€ í‚¤ì›Œë“œ 'login'")
        if candidates:
            reasons.append("ë¡œê·¸ì¸/íŒ¨ë„ í›„ë³´ ë§í¬ ì¡´ì¬")
        targets = [f.get("action") for f in login_forms if f.get("action")] + candidates
        targets = uniq(targets)[:10]
        findings.append({
            "tag": "login",
            "confidence": "high" if login_forms else "medium",
            "reason": "; ".join(reasons) or "ë¡œê·¸ì¸ ê´€ë ¨ ì‹ í˜¸",
            "targets": targets or [top_base(report.get("url", ""))],
            "suggested_templates": suggest_templates_for("login")
        })
    return findings

def detect_cms_stack(report: Dict[str, Any]) -> List[Dict[str, Any]]: # meta íƒœê·¸, script/link ê²½ë¡œ ë“±ì„ ë¶„ì„í•´ WordPress, Drupal, Jommla ê°™ì€ CMS í”ì ì„ íƒì§€
    findings = []
    dom = report.get("dom", {})
    meta = dom.get("meta", {}) or {}
    scripts = dom.get("scripts", []) or []
    links = dom.get("links", []) or []

    # WordPress í”ì 
    wp = ("generator" in meta and "wordpress" in str(meta.get("generator", "")).lower()) \
         or any("/wp-content/" in u or "/wp-includes/" in u for u in scripts + links)
    if wp:
        findings.append({
            "tag": "wordpress",
            "confidence": "high",
            "reason": "meta.generator ë˜ëŠ” /wp-content/ ê²½ë¡œ",
            "targets": [top_base(report.get("url", ""))],
            "suggested_templates": suggest_templates_for("wordpress") + ["tags:wp", "tags:wp-plugin"]
        })
        wp_plugins = [u for u in scripts + links if "/wp-content/plugins/" in u]
        if wp_plugins:
            findings.append({
                "tag": "wp-plugins",
                "confidence": "medium",
                "reason": f"í”ŒëŸ¬ê·¸ì¸ ê²½ë¡œ {len(wp_plugins)}ê°œ ë…¸ì¶œ",
                "targets": uniq(wp_plugins)[:20],
                "suggested_templates": ["tags:wp-plugins", "tags:wp-plugin"]
            })

    # ê¸°íƒ€ CMS í”ì 
    drupal = any("/sites/default/" in u for u in scripts + links)
    if drupal:
        findings.append({
            "tag": "cms",
            "confidence": "medium",
            "reason": "Drupal íŒ¨í„´(/sites/default/) ê°ì§€",
            "targets": [top_base(report.get("url", ""))],
            "suggested_templates": ["tags:cms"]
        })
    joomla = any("joomla" in u.lower() for u in scripts + links)
    if joomla:
        findings.append({
            "tag": "joomla",
            "confidence": "medium",
            "reason": "ë¦¬ì†ŒìŠ¤ ê²½ë¡œì— 'joomla'",
            "targets": [top_base(report.get("url", ""))],
            "suggested_templates": ["tags:joomla", "tags:cms"]
        })
    return findings

def detect_tech(report: Dict[str, Any]) -> List[Dict[str, Any]]: # fingerprints í•„ë“œì—ì„œ ì„œë²„ ê¸°ìˆ  ìŠ¤íƒ(nginx, php ë“±)ì„ ì¶”ì¶œ
    fp = report.get("fingerprints", {}) or {}
    techs = fp.get("tech", []) or []
    if not techs:
        return []
    return [{
        "tag": "tech",
        "confidence": "medium",
        "reason": f"ê¸°ìˆ  ìŠ¤íƒ: {', '.join(techs[:6])}",
        "targets": [top_base(report.get("url", ""))],
        "suggested_templates": suggest_templates_for("tech")
    }]

def detect_exposure(report: Dict[str, Any]) -> List[Dict[str, Any]]: # DOMì˜ ì£¼ì„/í…ìŠ¤íŠ¸ ë‹¨ì„œì—ì„œ API í‚¤, ë¡œê·¸, debug ë©”ì‹œì§€ ë“± ë¯¼ê° ì •ë³´ ë…¸ì¶œì„ íƒì§€
    leaks = (report.get("dom", {}) or {}).get("comments_or_text_leaks", []) or []
    exposure, info_leak, logs, debug = [], [], [], []
    for l in leaks:
        t = (l.get("type") or "").lower()
        if t in ["api_key", "apikey", "secret", "token"]:
            exposure.append(l)
        elif t in ["stack", "warning", "traceback", "exception", "log"]:
            logs.append(l)
        elif t == "debug":
            debug.append(l)
        else:
            info_leak.append(l)
    out = []
    if exposure:
        out.append({
            "tag": "exposure",
            "confidence": "high",
            "reason": "ë¯¼ê° ì •ë³´(API/Secret ë“±) ë…¸ì¶œ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": exposure[:5],
            "suggested_templates": ["tags:exposure", "tags:info-leak"]
        })
    if info_leak:
        out.append({
            "tag": "info-leak",
            "confidence": "medium",
            "reason": "ì£¼ì„/í…ìŠ¤íŠ¸ì˜ ì •ë³´ ëˆ„ì¶œ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": info_leak[:5],
            "suggested_templates": ["tags:info-leak"]
        })
    if logs:
        out.append({
            "tag": "logs",
            "confidence": "medium",
            "reason": "ìŠ¤íƒíŠ¸ë ˆì´ìŠ¤/ê²½ê³ /ë¡œê·¸ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": logs[:5],
            "suggested_templates": ["tags:logs"]
        })
    if debug:
        out.append({
            "tag": "debug",
            "confidence": "medium",
            "reason": "DEBUG í”Œë˜ê·¸ ë‹¨ì„œ",
            "targets": [top_base(report.get("url", ""))],
            "evidence": debug[:5],
            "suggested_templates": ["tags:debug"]
        })
    return out

def detect_osint(report: Dict[str, Any]) -> List[Dict[str, Any]]: # OSINT ë…¸ì¶œ ì •ë³´(ì´ë©”ì¼, ì†Œì…œ ë§í¬, ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŒ… ë“±)ë¥¼ íƒì§€
    osint = report.get("osint_exposure", {}) or {}
    emails = osint.get("emails", []) or []
    socials = osint.get("socials", []) or []
    open_dirs = osint.get("open_directory_ui", []) or []
    out = []
    if emails:
        out.append({
            "tag": "osint",
            "confidence": "high",
            "reason": "ë³´ì•ˆ/ì—°ë½ ì´ë©”ì¼",
            "targets": [top_base(report.get("url", ""))],
            "evidence": {"emails": emails[:10]},
            "suggested_templates": ["tags:osint"]
        })
    if socials:
        out.append({
            "tag": "osint-social",
            "confidence": "high",
            "reason": "ê³µì‹ ì†Œì…œ ë§í¬",
            "targets": socials[:10],
            "evidence": {"socials": socials[:10]},
            "suggested_templates": ["tags:osint-social"]
        })
    if open_dirs:
        out.append({
            "tag": "listing",
            "confidence": "medium",
            "reason": "ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŒ… UI",
            "targets": open_dirs[:10],
            "suggested_templates": ["tags:listing"]
        })
    return out

def detect_form_vulnerabilities(report: Dict[str, Any]) -> List[Dict[str, Any]]:
    """í¼ì´ ë°œê²¬ë˜ë©´ ê¸°ë³¸ì ì¸ ì›¹ ì·¨ì•½ì  í…ŒìŠ¤íŠ¸ ìë™ ìƒì„±"""
    findings = []
    
    # DOMì—ì„œ í¼ ë°ì´í„° ì¶”ì¶œ
    dom = report.get("dom", {})
    forms = dom.get("forms", []) or []
    attack_vectors = report.get("attack_vectors", {})
    form_vectors = attack_vectors.get("forms", []) if attack_vectors else []
    
    all_forms = forms + form_vectors
    if not all_forms:
        return findings
    
    base_url = top_base(report.get("url", ""))
    form_actions = []
    
    for form in all_forms:
        if isinstance(form, dict):
            action = form.get("action", "")
            method = form.get("method", "GET").upper()
            inputs = form.get("inputs", [])
            
            # í¼ ì•¡ì…˜ URL ì •ê·œí™”
            if action:
                if action.startswith("http"):
                    form_actions.append(action)
                else:
                    # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                    if action.startswith("/"):
                        form_actions.append(base_url.rstrip("/") + action)
                    else:
                        form_actions.append(base_url.rstrip("/") + "/" + action)
            
            # GET/POST í¼ì´ ìˆìœ¼ë©´ SQL Injection í…ŒìŠ¤íŠ¸ ìƒì„± (GET í¼ë„ SQL injection ê°€ëŠ¥)
            if inputs and len(inputs) > 0:
                findings.append({
                    "tag": "sqli",
                    "confidence": "high",  # GET í¼ë„ SQL injection ìœ„í—˜
                    "reason": f"{method} í¼ ë°œê²¬ (action={action}, inputs={len(inputs)}ê°œ) - SQL Injection ê°€ëŠ¥ì„±",
                    "targets": [action] if action else [base_url],
                    "suggested_templates": ["tags:sqli", "tags:injection", "tags:sqli-blind"]
                })
                
                # XSS í…ŒìŠ¤íŠ¸ë„ ì¶”ê°€ (GET/POST ëª¨ë‘ XSS ê°€ëŠ¥)
                if method == "POST":
                    findings.append({
                        "tag": "xss",
                        "confidence": "high", 
                        "reason": f"POST ì…ë ¥ í¼ ë°œê²¬ - XSS ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸",
                        "targets": [action] if action else [base_url],
                        "suggested_templates": ["tags:xss", "tags:xss-reflected", "tags:xss-stored"]
                    })
                else:
                    findings.append({
                        "tag": "xss",
                        "confidence": "medium", 
                        "reason": f"GET ì…ë ¥ í¼ ë°œê²¬ - XSS ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸",
                        "targets": [action] if action else [base_url],
                        "suggested_templates": ["tags:xss", "tags:xss-reflected"]
                    })
    
    # ì¼ë°˜ì ì¸ ì›¹ ì·¨ì•½ì  ìŠ¤ìº” ì¶”ê°€ (í¼ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´)
    if all_forms:
        findings.append({
            "tag": "web-vuln",
            "confidence": "high",
            "reason": f"ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ ({len(all_forms)}ê°œ í¼) - ì¼ë°˜ ì·¨ì•½ì  ìŠ¤ìº”",
            "targets": form_actions[:5] if form_actions else [base_url],
            "suggested_templates": ["tags:lfi", "tags:rfi", "tags:directory-traversal", "tags:file-upload", "tags:csrf"]
        })
    
    return findings

def add_universal_web_templates(report: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëŒ€í•´ ê¸°ë³¸ì ì¸ ëª¨ë“  ì›¹ ì·¨ì•½ì  í…œí”Œë¦¿ì„ ì¶”ê°€"""
    findings = []
    base_url = top_base(report.get("url", ""))
    
    # ê¸°ë³¸ ì›¹ ì·¨ì•½ì  í…œí”Œë¦¿ë“¤ - ëª¨ë“  ì›¹ì‚¬ì´íŠ¸ì— ì ìš©
    universal_templates = [
        {
            "tag": "sqli",
            "confidence": "medium",
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - SQL Injection ê¸°ë³¸ ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:sqli", "tags:injection", "tags:sqli-blind", "tags:sqli-time", "tags:mysql", "tags:postgresql", "tags:oracle"]
        },
        {
            "tag": "xss",
            "confidence": "medium", 
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - XSS ê¸°ë³¸ ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:xss", "tags:xss-reflected", "tags:xss-stored", "tags:xss-dom"]
        },
        {
            "tag": "lfi",
            "confidence": "medium",
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - Local File Inclusion ìŠ¤ìº”", 
            "targets": [base_url],
            "suggested_templates": ["tags:lfi", "tags:file-read", "tags:path-traversal"]
        },
        {
            "tag": "rfi",
            "confidence": "medium",
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - Remote File Inclusion ìŠ¤ìº”",
            "targets": [base_url], 
            "suggested_templates": ["tags:rfi", "tags:file-inclusion"]
        },
        {
            "tag": "directory-traversal",
            "confidence": "medium",
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - Directory Traversal ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:directory-traversal", "tags:path-traversal"]
        },
        {
            "tag": "csrf",
            "confidence": "low",
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - CSRF ê¸°ë³¸ ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:csrf"]
        },
        {
            "tag": "auth-bypass",
            "confidence": "medium",
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - Authentication Bypass ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:auth-bypass", "tags:authentication"]
        },
        {
            "tag": "info-disclosure",
            "confidence": "medium",
            "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°ì§€ - Information Disclosure ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:info-disclosure", "tags:exposure", "tags:config"]
        }
    ]
    
    findings.extend(universal_templates)
    
    # URL íŒ¨í„´ ê¸°ë°˜ ì¶”ê°€ í…œí”Œë¦¿
    url = report.get("url", "").lower()
    if any(pattern in url for pattern in ['/admin', '/login', '/dashboard', '/panel']):
        findings.append({
            "tag": "brute-force",
            "confidence": "high",
            "reason": "ê´€ë¦¬ì/ë¡œê·¸ì¸ í˜ì´ì§€ ê°ì§€ - Brute Force ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:brute-force", "tags:login", "tags:default-creds"]
        })
    
    if any(pattern in url for pattern in ['.php', '.asp', '.jsp', '/api']):
        findings.append({
            "tag": "rce",
            "confidence": "medium", 
            "reason": "ë™ì  ì›¹í˜ì´ì§€/API ê°ì§€ - RCE ìŠ¤ìº”",
            "targets": [base_url],
            "suggested_templates": ["tags:rce", "tags:command-injection", "tags:code-injection"]
        })
        
    return findings

def build_raw_findings(report: Dict[str, Any]) -> List[Dict[str, Any]]: # ìœ„ì˜ ëª¨ë“  ê°ì§€ê¸°ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì›ì‹œ findings ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¦
    detectors = [detect_panel_login, detect_cms_stack, detect_tech, detect_exposure, detect_osint, detect_form_vulnerabilities]
    findings = []
    for det in detectors:
        findings.extend(det(report))
    
    # ğŸ”¥ UNIVERSAL WEB TEMPLATES: ëª¨ë“  ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ê¸°ë³¸ í…œí”Œë¦¿ë“¤ ì¶”ê°€
    findings.extend(add_universal_web_templates(report))
    
    return findings

# -------------------------
# LLM ê²Œì´íŠ¸ (ë³´ì•ˆ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§)
# -------------------------
class LLMFindingDecision(BaseModel): # ë‹¨ì¼ findingì— ëŒ€í•œ LLM íŒì • êµ¬ì¡°ì²´ (tag, severity, run ì—¬ë¶€, rationale, references ë“±ì„ í¬í•¨)
    tag: str
    looks_vulnerable: bool
    severity: str = Field(..., description="one of: none, low, medium, high, critical")
    rationale: str
    references: List[str] = Field(default_factory=list)  # ex) OWASP, CWE ë§í¬ ë“±
    run_template: bool = Field(..., description="nuclei ì‹¤í–‰ ê°€ì¹˜ ì—¬ë¶€")

class LLMGateOutput(BaseModel): # LLM ì „ì²´ íŒì • ê²°ê³¼ êµ¬ì¡°ì²´(ì „ì²´ ìœ„í—˜ë„, ê°œë³„ decisions ë¦¬ìŠ¤íŠ¸)
    overall_risk: str = Field(..., description="none|low|medium|high|critical")
    decisions: List[LLMFindingDecision]

SYSTEM_PROMPT = """You are an EXTREMELY AGGRESSIVE security vulnerability scanner assistant. Your primary goal is MAXIMUM COVERAGE of all possible vulnerabilities.

CRITICAL RULES (ALWAYS FOLLOW):
- DEFAULT to run_template=true for ALL findings unless absolutely certain it's irrelevant
- ALWAYS set run_template=true for: sqli, xss, lfi, rfi, csrf, directory-traversal, auth-bypass, brute-force, rce, file-upload, info-disclosure
- EVERY web application should be scanned for ALL common vulnerabilities regardless of evidence
- If ANY form exists (GET or POST), IMMEDIATELY set run_template=true for sqli, xss, csrf
- If ANY dynamic content detected (.php, .asp, .jsp, /api, parameters), IMMEDIATELY set run_template=true for rce, sqli, lfi
- If ANY admin/login patterns (/admin, /login, /panel, /dashboard), IMMEDIATELY set run_template=true for brute-force, auth-bypass
- MINIMUM overall_risk should be "medium" for any web application
- MINIMUM severity should be "medium" for all major vulnerability types

EXTREME AGGRESSION POLICY:
- Consider EVERY URL as potentially vulnerable until proven otherwise  
- Assume ALL forms are vulnerable to injection attacks
- Assume ALL file parameters are vulnerable to LFI/RFI/traversal
- Assume ALL authentication mechanisms can be bypassed or brute-forced
- For ANY suspicious URL patterns, SET run_template=true AND severity="high"

TEMPLATE SELECTION:
- Use MULTIPLE tags per vulnerability type for maximum coverage
- Examples: ["tags:sqli", "tags:sqli-blind", "tags:sqli-time", "tags:injection", "tags:mysql", "tags:postgresql"]
- Examples: ["tags:xss", "tags:xss-reflected", "tags:xss-stored", "tags:xss-dom"]
- Examples: ["tags:lfi", "tags:rfi", "tags:file-read", "tags:path-traversal", "tags:directory-traversal"]

OUTPUT REQUIREMENTS:
- Output STRICT JSON only
- NEVER use run_template=false unless explicitly justified
- When in doubt, ALWAYS choose run_template=true
- Reference OWASP Top 10, CWE numbers when applicable
"""

USER_PROMPT_TEMPLATE = """Input JSON (from crawler):
{crawler_json}

Task:
For each finding candidate below, decide if it looks vulnerable in a way that justifies running a nuclei template. Consider severity (none|low|medium|high|critical) and set run_template true/false.

Candidates:
{candidates_json}

Output JSON schema:
{{
  "overall_risk": "none|low|medium|high|critical",
  "decisions": [
    {{
      "tag": "<string>",
      "looks_vulnerable": <true|false>,
      "severity": "none|low|medium|high|critical",
      "rationale": "<short reason>",
      "references": ["<optional refs>"],
      "run_template": <true|false>
    }}
  ]
}}
"""

# --- ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° í˜¸í™˜ ì²˜ë¦¬: gpt-5 ê³„ì—´ì€ temperature/top_p ë“± ë¯¸ì§€ì› ---
def _sampling_supported(model: str) -> bool:
    return not model.lower().startswith("gpt-5")

def _postprocess_and_fill_missing(raw_findings: List[Dict[str, Any]], llm_out: Dict[str, Any]) -> LLMGateOutput:
    """
    LLMì´ ì¼ë¶€ tagë§Œ íŒë‹¨í–ˆì„ ê²½ìš°, ëˆ„ë½ëœ tagëŠ” conservative defaultë¡œ ì±„ìš´ë‹¤.
    """
    try:
        parsed = LLMGateOutput(**llm_out)
    except Exception as e:
        raise ValueError(f"LLM output schema validation failed: {e}")

    decided_tags = {d.tag for d in parsed.decisions}
    all_tags = [f["tag"] for f in raw_findings]
    missing = [t for t in all_tags if t not in decided_tags]

    if missing:
        for t in missing:
            parsed.decisions.append(LLMFindingDecision(
                tag=t,
                looks_vulnerable=False,
                severity="low",
                rationale="no decision returned; defaulting to conservative low/no-run",
                references=[],
                run_template=False
            ))
        # overall_risk ì¬ê³„ì‚°(ê°€ì¥ ë†’ì€ severity)
        sev_rank = {"none":0,"low":1,"medium":2,"high":3,"critical":4}
        max_sev = "none"
        for d in parsed.decisions:
            if sev_rank.get(d.severity, 0) > sev_rank.get(max_sev, 0):
                max_sev = d.severity
        parsed.overall_risk = max_sev

    return parsed


def call_llm_gate(
    crawler_report: Dict[str, Any],
    raw_findings: List[Dict[str, Any]],
    max_candidates_per_call: Optional[int] = None  # ë„ˆë¬´ í° ì…ë ¥ì´ë©´ ë¶„í•  (ê¸°ë³¸: ì „ì²´ 1íšŒ)
) -> Optional[LLMGateOutput]:
    """
    OpenAI APIë¡œ findingsì˜ ìŠ¤ìº” ê°€ì¹˜/ì‹¬ê°ë„ë¥¼ íŒì •.
    - ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° í˜¸í™˜ ì²˜ë¦¬(ì˜ˆ: gpt-5*ëŠ” temperature/top_p ë¯¸ì§€ì›)
    - JSON íŒŒì‹± ê²¬ê³ í™” ë° ëˆ„ë½ íƒœê·¸ ë³´ì •
    - ì‹¤íŒ¨ ì‹œ None ë°˜í™˜(íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í´ë°±)
    """
    client, why = _get_openai_client()
    if client is None:
        print(f"[LLM GATE FALLBACK] {why}")
        return None

    # í›„ë³´ ë¶„í• (ì˜µì…˜) â€” ê¸°ë³¸ì€ ì „ì²´ í•œ ë²ˆì—
    batches: List[List[Dict[str, Any]]] = []
    if max_candidates_per_call and max_candidates_per_call > 0:
        for i in range(0, len(raw_findings), max_candidates_per_call):
            batches.append(raw_findings[i:i+max_candidates_per_call])
    else:
        batches = [raw_findings]

    # ê° ë°°ì¹˜ë¥¼ í˜¸ì¶œ í›„ ë³‘í•©
    merged_decisions: List[LLMFindingDecision] = []
    overall_max = "none"
    sev_rank = {"none":0,"low":1,"medium":2,"high":3,"critical":4}

    for batch_idx, batch in enumerate(batches):
        user_prompt = USER_PROMPT_TEMPLATE.format(
            crawler_json=json.dumps(crawler_report, ensure_ascii=False, indent=2),
            candidates_json=json.dumps(batch, ensure_ascii=False, indent=2),
        )

        # gpt-5*ëŠ” sampling íŒŒë¼ë¯¸í„° ì œê±°
        kwargs = {}
        # if _sampling_supported(OPENAI_MODEL):
        #     kwargs["temperature"] = 0.2

        last_err = None
        for attempt in range(2):
            try:
                resp = client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt}
                    ],
                    **kwargs
                )
                text = resp.choices[0].message.content.strip()
                m = re.search(r"\{.*\}\s*$", text, re.S)
                raw_json = m.group(0) if m else text
                data = json.loads(raw_json)
                parsed = _postprocess_and_fill_missing(batch, data)

                # ë³‘í•©
                merged_decisions.extend(parsed.decisions)
                if sev_rank.get(parsed.overall_risk, 0) > sev_rank.get(overall_max, 0):
                    overall_max = parsed.overall_risk
                break  # ë°°ì¹˜ ì„±ê³µí–ˆìœ¼ë©´ ë‹¤ìŒ ë°°ì¹˜ë¡œ
            except Exception as e:
                last_err = e
                time.sleep(0.5)
        else:
            print(f"[LLM GATE FALLBACK] batch {batch_idx} failed: {type(last_err).__name__}: {last_err}")
            return None  # ë°°ì¹˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í´ë°±

    # ìµœì¢… ë³‘í•© ê²°ê³¼(ë™ì¼ tag ì¤‘ë³µ ì‹œ ë§ˆì§€ë§‰ê°’ ìœ ì§€)
    final_by_tag: Dict[str, LLMFindingDecision] = {}
    for d in merged_decisions:
        final_by_tag[d.tag] = d
    final = LLMGateOutput(overall_risk=overall_max, decisions=list(final_by_tag.values()))
    return final

# -------------------------
# íœ´ë¦¬ìŠ¤í‹± ê²Œì´íŠ¸ (LLM ë¶ˆê°€ ì‹œ)
# -------------------------
SEV_ORDER = ["none", "low", "medium", "high", "critical"]

def heuristic_gate(raw_findings: List[Dict[str, Any]]) -> LLMGateOutput:
    decisions = []
    # ğŸ”¥ AGGRESSIVE POLICY: ëª¨ë“  ì›¹ ì·¨ì•½ì ì— ëŒ€í•´ í¬ê´„ì ìœ¼ë¡œ í…œí”Œë¦¿ ì‹¤í–‰
    for f in raw_findings:
        tag = f["tag"]
        sev = "medium"  # ê¸°ë³¸ê°’ì„ mediumìœ¼ë¡œ ìƒí–¥
        run = True      # ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½ (ì ê·¹ì  ìŠ¤ìº”)

        # ê³ ìœ„í—˜ ì·¨ì•½ì ë“¤
        if tag in ("exposure", "sqli", "xss", "rce", "lfi", "rfi"):
            sev, run = "high", True
        # ì¤‘ê°„ ìœ„í—˜ ì·¨ì•½ì ë“¤
        elif tag in ("panel", "login", "wp-plugins", "csrf", "file-upload", "directory-traversal"):
            sev, run = "medium", True
        # CMS ë° ê¸°ìˆ  ìŠ¤íƒ ì·¨ì•½ì ë“¤
        elif tag in ("wordpress", "cms", "joomla", "drupal", "php", "apache", "nginx"):
            sev, run = "medium", True
        # ì •ë³´ ëˆ„ì¶œ ê´€ë ¨
        elif tag in ("logs", "debug", "info-leak", "config-exposure"):
            sev, run = "medium", True
        # ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¼ë°˜ ì·¨ì•½ì ë“¤
        elif tag in ("web-vuln", "auth-bypass", "brute-force", "session-fixation"):
            sev, run = "high", True
        # ê¸°ìˆ  ì •ë³´ ìˆ˜ì§‘ë„ ìŠ¤ìº” ëŒ€ìƒìœ¼ë¡œ í¬í•¨
        elif tag in ("tech", "osint", "osint-social", "listing"):
            sev, run = "low", True   # ì •ë³´ì„±ì´ì§€ë§Œ ìŠ¤ìº”ì€ ìˆ˜í–‰

        decisions.append(LLMFindingDecision(
            tag=tag,
            looks_vulnerable=run,
            severity=sev,
            rationale="aggressive heuristic policy - comprehensive vulnerability scanning",
            references=[],
            run_template=run
        ))

    # overall_risk = ìµœê³  ë“±ê¸‰ (ìµœì†Œ mediumìœ¼ë¡œ ì„¤ì •)
    max_sev = "medium"  # ê¸°ë³¸ ìµœì†Œ ìœ„í—˜ë„ë¥¼ mediumìœ¼ë¡œ ì„¤ì •
    for d in decisions:
        if SEV_ORDER.index(d.severity) > SEV_ORDER.index(max_sev):
            max_sev = d.severity

    return LLMGateOutput(overall_risk=max_sev, decisions=decisions)

# -------------------------
# nuclei ì‹¤í–‰/ë¯¸ì‹¤í–‰ ë¶„ë¦¬
# -------------------------
def split_to_run_skip(raw_findings: List[Dict[str, Any]], # findingsë¥¼ to_run(ìŠ¤ìºë‹ ì‹¤í–‰)ê³¼ to_skip(ì‹¤í–‰ ì œì™¸)ìœ¼ë¡œ ë‚˜ëˆˆë‹¤.
                      gate: LLMGateOutput,
                      allow_tags: Set[str]) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    to_run, to_skip = [], []
    # tag -> run_template ë§µ
    runmap = {d.tag: d.run_template for d in gate.decisions}
    sevmap = {d.tag: d.severity for d in gate.decisions}
    ratemap = {d.tag: d.rationale for d in gate.decisions}

    for f in raw_findings:
        tag = f["tag"]
        f["llm_severity"] = sevmap.get(tag, "low")
        f["llm_rationale"] = ratemap.get(tag, "decision missing")
        if runmap.get(tag, False):
           to_run.append(f)
        else:
            to_skip.append(f)

    return to_run, to_skip

import os
import json
import argparse
from typing import Dict, Any, Optional

# ---- ê³µí†µ ì„¤ì • ----
DEFAULT_ALLOW = ",".join(sorted(ALLOW_TAGS_ALL)) # í—ˆìš©ë˜ëŠ” íƒœê·¸ ì „ì²´ ëª©ë¡ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¬¸ìì—´ë¡œ ë³´ê´€

def in_notebook() -> bool:
    """Jupyter/Colabì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ íŒë³„."""
    try:
        from IPython import get_ipython  # noqa
        return True
    except Exception:
        return False

def run_pipeline_from_report(report: Dict[str, Any], allow: str = DEFAULT_ALLOW) -> Dict[str, Any]:
    allow_tags = set([t.strip() for t in (allow or "").split(",") if t.strip()])
    raw_findings = build_raw_findings(report)

    # ğŸ”¥ AGGRESSIVE POLICY: findingsê°€ ì ë”ë¼ë„ ê¸°ë³¸ ì›¹ ì·¨ì•½ì ë“¤ì„ ê°•ì œë¡œ ì¶”ê°€
    if len(raw_findings) < 5:  # ê¸°ë³¸ í…œí”Œë¦¿ ìˆ˜ë³´ë‹¤ ì ìœ¼ë©´ ë” ì¶”ê°€
        print(f"[âš¡] ê³µê²©ì  ì •ì±…: {len(raw_findings)}ê°œ findings ê°ì§€, ì¶”ê°€ ê¸°ë³¸ í…œí”Œë¦¿ë“¤ ê°•ì œ ì¶”ê°€")
        base_url = top_base(report.get("url", ""))
        # ìµœì†Œí•œì˜ ê¸°ë³¸ í…œí”Œë¦¿ë“¤ì€ ë¬´ì¡°ê±´ ì‹¤í–‰
        mandatory_templates = [
            {
                "tag": "comprehensive-scan",
                "confidence": "high",
                "reason": "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ëŒ€ìƒ - í¬ê´„ì  ê¸°ë³¸ ì·¨ì•½ì  ìŠ¤ìº” ê°•ì œ ì‹¤í–‰",
                "targets": [base_url],
                "suggested_templates": [
                    "tags:sqli", "tags:xss", "tags:lfi", "tags:rfi", 
                    "tags:directory-traversal", "tags:auth-bypass", 
                    "tags:info-disclosure", "tags:csrf", "tags:brute-force"
                ]
            }
        ]
        raw_findings.extend(mandatory_templates)

    # LLM ê²Œì´íŠ¸ ì‹¤í–‰ (ì‹¤íŒ¨ ì‹œ íœ´ë¦¬ìŠ¤í‹± í´ë°±)
    gate = call_llm_gate(report, raw_findings) or heuristic_gate(raw_findings)
    
    # ğŸ”¥ SAFETY NET: LLMì´ ë„ˆë¬´ ë³´ìˆ˜ì ì´ë©´ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ê°•ì œ ì˜¤ë²„ë¼ì´ë“œ
    run_count = sum(1 for d in gate.decisions if d.run_template)
    if run_count < 3:  # ì‹¤í–‰í•  í…œí”Œë¦¿ì´ 3ê°œ ë¯¸ë§Œì´ë©´
        print(f"[âš¡] LLM ë„ˆë¬´ ë³´ìˆ˜ì  ({run_count}ê°œ ì‹¤í–‰) - íœ´ë¦¬ìŠ¤í‹± ì •ì±…ìœ¼ë¡œ ê°•ì œ ì˜¤ë²„ë¼ì´ë“œ")
        gate = heuristic_gate(raw_findings)
    
    to_run, to_skip = split_to_run_skip(raw_findings, gate, allow_tags)
    return {"overall_risk": gate.overall_risk, "to_run": to_run, "to_skip": to_skip}


def run_pipeline_from_file(crawler_json_path: str, allow: str = DEFAULT_ALLOW) -> Dict[str, Any]:
    """íŒŒì¼ ê²½ë¡œë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰."""
    with open(crawler_json_path, "r", encoding="utf-8") as f:
        report = json.load(f)
    return run_pipeline_from_report(report, allow=allow)

def main(crawler_json: Optional[str] = None,
         allow: str = DEFAULT_ALLOW,
         report_obj: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    ê³µí†µ ì§„ì…ì :
    - ë…¸íŠ¸ë¶ì—ì„œëŠ” main(report_obj=...) ë˜ëŠ” main(crawler_json=...)ë¡œ ì§ì ‘ í˜¸ì¶œ
    - .py CLIì—ì„œëŠ” argparseë¡œ ê°’ì„ ë°›ì•„ main(crawler_json=...) í˜¸ì¶œ
    """
    if report_obj is not None:
        return run_pipeline_from_report(report_obj, allow=allow)
    if crawler_json:
        return run_pipeline_from_file(crawler_json, allow=allow)
    raise ValueError("main()ì—ëŠ” crawler_json(íŒŒì¼ ê²½ë¡œ) ë˜ëŠ” report_obj(dict) ì¤‘ í•˜ë‚˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

def main_cli() -> None:
    import argparse

    ap = argparse.ArgumentParser()
    ap.add_argument("crawler_json", help="crawler report json path")
    ap.add_argument("--allow", type=str, default=DEFAULT_ALLOW,
                    help="comma-separated tags to allow")
    ap.add_argument("--author", type=str, default="ksko", help="YAML author metadata")
    ap.add_argument("--id-prefix", type=str, default="auto-gen", help="YAML id prefix")
    ap.add_argument("--out", type=str, help="YAML íŒŒì¼ ì €ì¥ ê²½ë¡œ (ì˜ˆ: nuclei_auto.yaml)")
    ap.add_argument("--print-json", action="store_true", help="JSON ê²°ê³¼ë„ ì¶œë ¥")
    args = ap.parse_args()

    # ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    out = main(crawler_json=args.crawler_json, allow=args.allow)

    if args.print_json:
        print(json.dumps(out, ensure_ascii=False, indent=2))

    # nuclei YAML ìƒì„±
    yaml_out = findings_to_nuclei_yaml(
        out,
        base_id_prefix=args.id_prefix,
        author=args.author
    )

    if args.out:
        with open(args.out, "w", encoding="utf-8") as f:
            f.write(yaml_out)
        print(f"[âœ“] YAML ì €ì¥ ì™„ë£Œ: {args.out}")
    else:
        print(yaml_out)

import re, yaml, json
from urllib.parse import urlparse
from typing import Dict, Any, List, Optional

def _to_rel_path(u: str) -> str:
    if re.match(r"^https?://", u, re.I):
        p = urlparse(u).path or "/"
        if not p.startswith("/"):
            p = "/" + p
        return "{{BaseURL}}" + p
    if not u.startswith("/"):
        u = "/" + u
    return "{{BaseURL}}" + u

def _only_urls(refs: List[str]) -> List[str]:
    return [r for r in (refs or []) if r.startswith("http")]

def _basic_matchers_for(tag: str):
    tag = (tag or "").lower()
    if tag in ("panel", "login"):
        return {
            "matchers-condition": "and",
            "matchers": [
                {"type": "status", "status": [200, 302, 401, 403]},
                {"type": "word", "words": ["login", "admin", "sign in"], "condition": "or", "part": "body"}
            ]
        }
    if tag in ("wordpress", "wp-plugins"):
        return {
            "matchers-condition": "and",
            "matchers": [
                {"type": "status", "status": [200, 302]},
                {"type": "word", "words": ["/wp-content/", "WordPress"], "condition": "or", "part": "body"}
            ]
        }
    if tag in ("exposure", "logs", "listing"):
        return {
            "matchers-condition": "or",
            "matchers": [
                {"type": "status", "status": [200]},
                {"type": "word", "words": ["Index of /", "Traceback", "Warning:"], "part": "body"}
            ]
        }
    return {"matchers": [{"type": "status", "status": [200, 302, 401, 403]}]}

def findings_to_nuclei_yaml(
    pipeline_out: Dict[str, Any],
    base_id_prefix: str = "auto-gen",
    author: str = "ksko",
    add_metadata: Optional[Dict[str, Any]] = None
) -> str:
    add_metadata = add_metadata or {"source": "auto-pipeline"}
    findings = pipeline_out.get("to_run", []) or []
    yamls = []
    for idx, f in enumerate(findings, 1):
        tag = f.get("tag", "unknown")
        sev = (f.get("llm_severity") or "low").lower()
        rationale = f.get("llm_rationale") or f.get("reason") or ""
        refs = _only_urls(f.get("suggested_templates") or [])
        targets = f.get("targets") or []

        paths, seen = [], set()
        for t in targets:
            p = _to_rel_path(str(t))
            if p not in seen:
                seen.add(p)
                paths.append(p)

        tpl = {
            "id": f"{base_id_prefix}-{tag}-{idx}",
            "info": {
                "name": f"Auto-detected {tag}",
                "author": author,
                "severity": sev,
                "description": rationale,
                "reference": refs,
                "tags": [tag],
                "metadata": {**add_metadata, "rule": tag}
            },
            "http": []
        }
        if paths:
            http_block = {
                "method": "GET",
                "path": paths,
                "redirects": True,
                "max-redirects": 2,
                "stop-at-first-match": True,
            }
            http_block.update(_basic_matchers_for(tag))
            tpl["http"].append(http_block)
        yamls.append(tpl)
    return yaml.dump_all(yamls, sort_keys=False, allow_unicode=True)

if __name__ == "__main__":

    main_cli()